<h1 align="center"> Discovering and Explaining the Non-Causality of Deep Learning in SAR ATR </h1> 

<h5 align="center"><em> Weijie Li (æç®æ°), Wei Yang (æ¨å¨), Li Liu (åˆ˜ä¸½), Wenpeng Zhang (å¼ æ–‡é¹), and Yongxiang (åˆ˜æ°¸ç¥¥) </em></h5>

<p align="center">
<a href="https://arxiv.org/abs/2304.00668"><img src="https://img.shields.io/badge/Paper-arxiv-red"></a>
<a href="https://ieeexplore.ieee.org/document/10100951"><img src="https://img.shields.io/badge/Paper-IEEE%20GRSL-red"></a>
</p>

<details>
  <summary>Table of Contents</summary>
  <ol>
    <li><a href="#Introduction">Catalog</a></li>
    <li><a href="#data">License</a></li>
    <li><a href="#exp1">Acknowledgement</a></li>
    <li><a href="#exp5">Citation</a></li>
  </ol>
</details>

## Introduction
This is the official repository for the paper â€œDiscovering and Explaining the Non-Causality of Deep Learning in SAR ATRâ€. 

è¿™é‡Œæ˜¯è®ºæ–‡ â€œDiscovering and Explaining the Non-Causality of Deep Learning in SAR ATR (å‘ç°å¹¶è§£é‡ŠSARç›®æ ‡è¯†åˆ«ä¸­æ·±åº¦å­¦ä¹ çš„éå› æœæ€§) â€çš„ä»£ç åº“ã€‚

**Abstract:** In recent years, deep learning has been widely used in synthetic aperture radar (SAR) automatic target recognition (ATR) and achieved excellent performance on the moving and stationary target acquisition and recognition (MSTAR) dataset. However, due to constrained imaging conditions, MSTAR has data biases such as background correlation, that is, background clutter properties have a spurious correlation with target classes. Deep learning can overfit clutter to reduce training errors. Therefore, the degree of overfitting for clutter reflects the noncausality of deep learning in SAR ATR. Existing methods only qualitatively analyze this phenomenon. In this letter, we quantify the contributions of different regions to target recognition based on the Shapley value. The Shapley value of clutter measures the degree of overfitting. Moreover, we explain how data bias and model bias contribute to noncausality. Concisely, data bias leads to comparable signal-to-clutter ratios (SCR) and clutter textures in training and test sets. And various model structures have different degrees of overfitting for these biases. The experimental results of various models under standard operating conditions (SOCs) on the MSTAR dataset support our conclusions. 

**æ‘˜è¦ï¼š** è¿‘å¹´æ¥ï¼Œæ·±åº¦å­¦ä¹ åœ¨åˆæˆå­”å¾„é›·è¾¾ï¼ˆSARï¼‰è‡ªåŠ¨ç›®æ ‡è¯†åˆ«ï¼ˆATRï¼‰ä¸­å¾—åˆ°äº†å¹¿æ³›åº”ç”¨ï¼Œå¹¶åœ¨ç§»åŠ¨å’Œé™æ­¢ç›®æ ‡è·å–ä¸è¯†åˆ«ï¼ˆMSTARï¼‰æ•°æ®é›†ä¸Šå–å¾—äº†ä¼˜å¼‚çš„æ€§èƒ½ã€‚ç„¶è€Œï¼Œç”±äºæˆåƒæ¡ä»¶çš„é™åˆ¶ï¼ŒMSTAR å­˜åœ¨èƒŒæ™¯ç›¸å…³æ€§ç­‰æ•°æ®åå·®ï¼Œå³èƒŒæ™¯æ‚æ³¢å±æ€§ä¸ç›®æ ‡ç±»åˆ«å­˜åœ¨è™šå‡ç›¸å…³æ€§ã€‚ä½¿å¾—æ·±åº¦å­¦ä¹ å¯ä»¥å¯¹æ‚æ³¢è¿›è¡Œè¿‡æ‹Ÿåˆï¼Œä»¥å‡å°‘è®­ç»ƒè¯¯å·®ã€‚å› æ­¤ï¼Œæ‚æ³¢çš„è¿‡æ‹Ÿåˆç¨‹åº¦åæ˜ äº†æ·±åº¦å­¦ä¹ åœ¨ SAR ATR ä¸­çš„éå› æœæ€§ã€‚ç›¸æ¯”ä¸ç°æœ‰å¯¹è¯¥ç°è±¡çš„å®šæ€§åˆ†æè€Œè¨€ï¼Œæˆ‘ä»¬åœ¨æœ¬æ–‡ä¸­æ ¹æ® Shapley å€¼é‡åŒ–äº†ä¸åŒåŒºåŸŸå¯¹ç›®æ ‡è¯†åˆ«çš„è´¡çŒ®ï¼Œå°†æ‚æ³¢çš„ Shapley å€¼è¡¡é‡è¿‡æ‹Ÿåˆçš„ç¨‹åº¦ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜è§£é‡Šäº†æ•°æ®åå·®å’Œæ¨¡å‹åå·®æ˜¯å¦‚ä½•å¯¼è‡´éç›¸å…³æ€§çš„ã€‚ç®€è€Œè¨€ä¹‹ï¼Œæ•°æ®åå·®ä¼šå¯¼è‡´è®­ç»ƒé›†å’Œæµ‹è¯•é›†ä¸­çš„ä¿¡å™ªæ¯”ï¼ˆSCRï¼‰å’Œæ‚æ³¢çº¹ç†å…·æœ‰ç›¸ä¼¼æ€§ã€‚è€Œä¸åŒçš„æ¨¡å‹ç»“æ„å¯¹è¿™äº›åå·®æœ‰ä¸åŒç¨‹åº¦çš„è¿‡æ‹Ÿåˆã€‚å„ç§æ¨¡å‹åœ¨ MSTAR æ•°æ®é›†æ ‡å‡†æ“ä½œæ¡ä»¶ï¼ˆSOCï¼‰çš„å®éªŒç»“æœæ”¯æŒäº†æˆ‘ä»¬çš„ç»“è®ºã€‚

We analyze the contributions and interactions of targets, clutter, and shadow regions during training for the MSTAR dataset. The contribution of clutter can be used as a quantitative indicator of the non-causality of deep learning. As shown in the Figure below, an example of clutter and bias is that the blue clutter contribution significantly impacts the classification of most targets. Besides, the SCR for each class in the training and test sets are very similar, indicating a background bias introduced during data collection.

æˆ‘ä»¬åˆ†æäº†ç›®æ ‡ã€æ‚æ³¢å’Œé˜´å½±åŒºåŸŸåœ¨ MSTAR æ•°æ®é›†è®­ç»ƒè¿‡ç¨‹ä¸­çš„è´¡çŒ®å’Œç›¸äº’ä½œç”¨ã€‚æ‚æ³¢çš„è´¡çŒ®å¯ä½œä¸ºæ·±åº¦å­¦ä¹ éå› æœå…³ç³»çš„é‡åŒ–æŒ‡æ ‡ã€‚å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œæ‚æ³¢å’Œè¿‡æ‹Ÿåˆçš„ä¸€ä¸ªä¾‹å­æ˜¯ï¼Œè“è‰²æ‚æ³¢çš„è´¡çŒ®æå¤§åœ°å½±å“äº†å¤§å¤šæ•°ç›®æ ‡çš„åˆ†ç±»ã€‚æ­¤å¤–ï¼Œè®­ç»ƒé›†å’Œæµ‹è¯•é›†ä¸­æ¯ä¸ªç±»åˆ«çš„ SCR éƒ½éå¸¸ç›¸ä¼¼ï¼Œè¿™è¡¨æ˜åœ¨æ•°æ®æ”¶é›†è¿‡ç¨‹ä¸­å¼•å…¥äº†èƒŒæ™¯åå·®ã€‚

<figure>
<div align="center">
<img src=example/class_scr_convenext.jpg width="90%">
</div>
</figure>

## data
The folder includes MSTAR images under SOC and SARbake segmentation files. 

è¯¥æ–‡ä»¶å¤¹åŒ…æ‹¬ SOC ä¸‹çš„ MSTAR å›¾åƒä»¥åŠ SARbake åˆ†å‰²æ–‡ä»¶ã€‚

```bash
SOC: Ten classes of target recognition under standard conditions (JPEG-E)  
SARbake: Corresponding segmented dataset  
JPEG: Linear mapping  
JPEG-E: Linear mapping and contrast enhancement  
```

```bash
SOC: æ ‡å‡†æ¡ä»¶ä¸‹çš„åç±»ç›®æ ‡è¯†åˆ« (JPEG-E)  
SARbake: å¯¹åº”çš„ç›®æ ‡ã€é˜´å½±å’ŒèƒŒæ™¯åˆ†å‰²æ–‡ä»¶
JPEG: å¯¹äºåŸå§‹å¤æ•°æ•°æ®çš„å¹…åº¦å›¾åƒè¿›è¡Œäº†çº¿æ€§æ˜ å°„
JPEG-E: å¯¹äºåŸå§‹å¤æ•°æ•°æ®çš„å¹…åº¦å›¾åƒè¿›è¡Œäº†çº¿æ€§æ˜ å°„å’Œå¯¹æ¯”åº¦å¢å¼º
```

## exp1
ShapleyValue_Demo.py is a demo of calculating the Shapley value and binary Shapley interaction.

ShapleyValue_Demo.py æ˜¯ä¸€ä¸ªè®¡ç®—æ²™æ™®åˆ©å€¼å’ŒäºŒå…ƒæ²™æ™®åˆ©å€¼äº¤äº’çš„demoã€‚

```python
from exp1.DataLoad import load_data, load_test
from exp1.TrainTest import model_train, model_shapely, model_test, class_model_shapely
from model.Model import A_ConvNet

train_all, label_name = load_data(arg.data_path + 'TRAIN')
train_loader = torch.utils.data.DataLoader(train_all, batch_size=arg.batch_size, shuffle=True)

model = A_ConvNet(num_classes=len(label_name))
opt = torch.optim.Adam(model.parameters(), lr=arg.lr)

for epoch in tqdm(range(1, arg.epochs + 1)):
    model_train(model=model, data_loader=train_loader, opt=opt)
    # calculate shapely value and binary Shapley interaction of each epoch
    history = model_shapely(model=model, data_loader=train_loader, his=history)
    
# calculate shapely value of each class
clu, tar, sha = class_model_shapely(model=model, data_loader=train_loader, label_length=len(label_name)) 
```

SCR_signal_to_clutter.py calculate the clutter mean and SCR of each class.

SCR_signal_too_clutter.py ç”¨äºè®¡ç®—æ¯ä¸ªç±»åˆ«çš„æ‚æ³¢å‡å€¼å’Œ SCRã€‚

## exp5
Add SCR re-weighting during training to investigate whether changing the SCR would affect the degree of overfitting for clutter.

åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æ·»åŠ  SCR é‡åŠ æƒä»¥ç ”ç©¶æ”¹å˜SCRæ˜¯å¦ä¼šå½±å“å¯¹äºæ‚æ³¢è¿‡æ‹Ÿåˆç¨‹åº¦ã€‚

## model
Code for the eight models used for our experiment.

æˆ‘ä»¬å®éªŒçš„å…«ä¸ªæ¨¡å‹çš„ä»£ç ã€‚

## Acknowledgement

Many thanks to the research [SARbake](https://data.mendeley.com/datasets/jxhsg8tj7g/3).


## Statement

- This project is released under the [Attribution-NonCommercial 4.0 International](LICENSE).
- Any questions please contact us at lwj2150508321@sina.com. 
- If you find our work is useful, please give us ğŸŒŸ in GitHub and cite our paper in the following BibTex format:

```
@ARTICLE{li2023discovering,
  author={Li, Weijie and Yang, Wei and Liu, Li and Zhang, Wenpeng and Liu, Yongxiang},
  journal={IEEE Geoscience and Remote Sensing Letters}, 
  title={Discovering and Explaining the Noncausality of Deep Learning in SAR ATR}, 
  year={2023},
  volume={20},
  number={},
  pages={1-5},
  doi={10.1109/LGRS.2023.3266493}
}

```

